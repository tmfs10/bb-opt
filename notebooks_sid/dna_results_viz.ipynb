{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/cluster/sj1/bb_opt/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import collect_stats as cs\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collect_stats as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_folder = '/cluster/sj1/bb_opt/experiments'\n",
    "test_filepath = '/cluster/sj1/bb_opt/data/tatsu_pbm/test_files'\n",
    "filedir = '/cluster/sj1/bb_opt/data/paper_data2'\n",
    "num_tfs_to_test = 38\n",
    "batches = [10, 20, 100, 200]\n",
    "batches = [10]\n",
    "num_acks = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(test_filepath, 'r') as f:\n",
    "    filenames = [k.strip() for k in f.readlines()][:num_tfs_to_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, exp=np.exp):\n",
    "  return 1.0 / (1.0 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    'HESX1_E149K_R1_8mers.txt',\n",
    "    'EGR2_D383Y_R1_8mers.txt',\n",
    "    'BCL6_H676Y_R1_8mers.txt',\n",
    "    'ARX_L343Q_R1_8mers.txt',\n",
    "    'CRX_E80A_R1_8mers.txt',\n",
    "    'ESX1_K193R_R1_8mers.txt',\n",
    "    'FOXC1_F112S_R1_8mers.txt',\n",
    "    'GFI1B_A204T_R1_8mers.txt',\n",
    "    'GFI1_L400F_R1_8mers.txt',\n",
    "    'HOXC4_N178S_R1_8mers.txt',\n",
    "    'HOXD13_I322L_R1_8mers.txt',\n",
    "    'ISX_R83Q_R1_8mers.txt',\n",
    "    'KLF11_R402Q_R1_8mers.txt',\n",
    "    'KLF1_E325K_R1_8mers.txt',\n",
    "    'MSX2_P148H_R1_8mers.txt',\n",
    "    'NKX2-5_K183E_R1_8mers.txt',\n",
    "    'NR1H4_C144R_R1_8mers.txt',\n",
    "    'NR2E3_G56R_R1_8mers.txt',\n",
    "    'OVOL2_D228E_R1_8mers.txt',\n",
    "    'PAX3_G48R_R1_8mers.txt',\n",
    "    'PAX4_R183C_R1_8mers.txt',\n",
    "    'PAX6_A79E_R1_8mers.txt',\n",
    "    'PAX7_P112L_R1_8mers.txt',\n",
    "    'PBX4_R215Q_R1_8mers.txt',\n",
    "    'PHOX2B_Q143R_R1_8mers.txt',\n",
    "    'PITX2_L100Q_R1_8mers.txt',\n",
    "    'POU3F4_A237G_R1_8mers.txt',\n",
    "    'POU4F3_K277R_R1_8mers.txt',\n",
    "    'POU6F2_E639K_R1_8mers.txt',\n",
    "    'PROP1_R112Q_R1_8mers.txt',\n",
    "    'SIX6_H141N_R1_8mers.txt',\n",
    "    'SNAI2_D119E_R1_8mers.txt',\n",
    "    'VAX2_L139M_R1_8mers.txt',\n",
    "    'VENTX_E101K_R1_8mers.txt',\n",
    "    'VSX1_G160D_R1_8mers.txt',\n",
    "    'WT1_F392L_R1_8mers.txt',\n",
    "    'ZNF200_H322Y_R1_8mers.txt',\n",
    "    'ZNF655_E327G_R1_8mers.txt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_max = {}\n",
    "tf_labels = {}\n",
    "for tf in filenames:\n",
    "    labels = np.load(filedir + \"/\" + tf + \"/labels.npy\")\n",
    "    labels = np.log(labels)\n",
    "    tf_max[tf] = float(labels.max())\n",
    "    tf_labels[tf] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arrs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collect_stats as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_read = {\n",
    "    #'ensemble7/o_none_ucb_modelseed_': [None, 'e7'],\n",
    "    #'ensemble7/o_none_ucb_ucb_step_0.1_modelseed_': [None, 'e7_ucb_step_0.1'],\n",
    "    #'ensemble7/o_none_ucb_maxvar_g000510204080_modelseed_': [None, 'e7_maxvar_g80'],\n",
    "    #'ensemble7/o_none_ucb_maxinoutvar_g000510204080_modelseed_': [None, 'e7_inoutvar_g80'],\n",
    "    #'ensemble7/o_none_ucb_maxinvar_g000510204080_modelseed_': [None, 'e7_invar_g80'],\n",
    "    #'ensemble7/o_none_ucb_dataseed_modelseed_': [None, 'e7'],\n",
    "    #'ensemble7/o_none_ucb_invar_g000510204080_dataseed_modelseed_' : [None, 'e7_datarand_invar_g80'],\n",
    "    #'ensemble7/o_none_ucb_maxvar_g000510204080_dataseed_modelseed_' : [None, 'e7_maxvar_g80'],\n",
    "    #'ensemble7/o_none_ucb_inoutvar_g000510204080_dataseed_modelseed_': [None, 'e7_datarand_inoutvar_g80'],\n",
    "    #'ensemble7/o_none_ucb_maxvar_inverse_g000510204080_': [None, 'MODD'],\n",
    "    #'ensemble9/o_none_ucb_modelseed_': [None, 'e9'],\n",
    "    #'ensemble9/o_none_ucb_maxvar_g000510204080_modelseed_': [None, 'e9_maxvar_g80'],\n",
    "    #'ensemble9/o_none_ucb_maxinvar_g000510204080_modelseed_': [None, 'e9_invar_g80'],\n",
    "    #'ensemble9/o_none_ucb_maxinoutvar_g000510204080_modelseed_': [None, 'e9_inoutvar_g80'],\n",
    "    #'ensemble7/o_kriging_believer_kb_modelseed_': [None, 'e7_kb'],\n",
    "    #'ensemble7/o_empirical_kb_div_3_modelseed_': [None, 'e7_empirical_kb'],\n",
    "    #'ensemble7/o_empirical_kb_ucb_weighted_div_10_modelseed_': [None, 'e7_wekb_div10'],\n",
    "    #'ensemble7/o_empirical_kb_ucb_weighted_0.5_div_10_modelseed_': [None, 'e7_wekb_0.5_div10'],\n",
    "    #'ensemble7/o_empirical_kb_ucb_weighted_mean_0.5_div_10_modelseed_': [None, 'e7_wekb_mean_0.5_div10'],\n",
    "    #'ensemble7/o_kb_dataseed_modelseed_': [None, 'e7_datarand_kb'],\n",
    "    #'ensemble10/o_kb_dataseed_modelseed_': [None, 'e10_datarand_kb'],\n",
    "    #'ensemble10/o_empirical_kb_ucb_weighted_0.5_div_10_dataseed_modelseed_': [None, 'e10_datarand_wekb_div10'],\n",
    "    #'ensemble11/o_kb_dataseed_modelseed_': [None, 'e11_datarand_kb'],\n",
    "    #'ensemble11/o_empirical_kb_ucb_weighted_0.5_div_10_dataseed_modelseed_': [None, 'e11_datarand_wekb_div10'],\n",
    "    #'ensemble11/o_kb_malaria_dataseed_modelseed_': [None, 'mal_datarand_kb'],\n",
    "    #'ensemble11/o_empirical_kb_malaria_ucb_weighted_0.5_div_10_dataseed_modelseed_': [None, 'mal_datarand_wekb_div10'],\n",
    "    #'ensemble11/o_kb_nolog_malaria_dataseed_modelseed_': [None, 'mal_datarand_kb_nolog'],\n",
    "    #'ensemble12/o_none_ucb_': [None, 'e7_2'],\n",
    "    #'ensemble12/o_none_ucb_maxinvar_g000510204080_': [None, 'maxinvar2'],\n",
    "    #'ensemble12/o_none_ucb_maxvar_g000510204080_': [None, 'maxvar2'],\n",
    "    #'ensemble12/o_none_ucb_maxvar_id_g000510204080_': [None, 'modr2'],\n",
    "    #'ensemble13/o_info_mves_div_5_minhsic_1_': [None, 'mves_div_5_minhsic_1'],\n",
    "    #'ensemble13/o_info_mves_div_5_minhsic_0.05_bs_0_': [None, 'mves_bs_0'],\n",
    "    #'ensemble13/o_none_ucb_': [None, 'e13'],\n",
    "    #'ensemble13/o_pdts_ucb_rand_randdiv_3_': [None, 'pdts_randdiv_3'],\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_5_minhsic_0.05_bs_0_': [None, 'mves_bs_0_it20'],\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_5_minhsic_0.05_bs_0_fill_pdts_': [None, 'mves_bs_0_it20_fp'],\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_5_minhsic_0.0_bs_0_fill_pdts_': [None, 'mves_bs_0_it20_fp_mh_0'],\n",
    "    #'ensemble13_init_train_20/o_none_ucb_': [None, 'e13_it20'],\n",
    "    #'ensemble13_init_train_20/o_none_ucb_rand_randdiv_3_': [None, 'e13_it20_randdiv_3'],\n",
    "    #'ensemble13_init_train_20/o_none_ucb_rand_randdiv_2_': [None, 'e13_it20_randdiv_2'],\n",
    "    #'ensemble13_init_train_20/o_none_ucb_rand_randdiv_1_': [None, 'e13_it20_randdiv_1'],\n",
    "    #'ensemble13_init_train_20/o_info_rand_mves_div_5_randdiv_1_': [None, 'mves_it20_fucb_randdiv_1'],\n",
    "    #'ensemble13_init_train_20/o_ei_ucb_': [None, 'ei_it20'],\n",
    "    #'ensemble13_init_train_20/o_pdts_ucb_rand_div_5_': [None, 'pdts_rand_div_5'],\n",
    "    #'ensemble13_init_train_20/o_pdts_ucb_rand_div_3_': [None, 'pdts_rand_div_3'],\n",
    "    #'ensemble13_init_train_20/o_info_rand_mves_div_5_fucb_randdiv_3_': [None, 'mves_it20_div_5_randdiv_3_fucb'],\n",
    "    #'ensemble13_init_train_20/o_info_rand_mves_div_5_fp_randdiv_3_': [None, 'mves_it20_div_5_randdiv_3_fp'],\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_5_minhsic_0.05_bs_0.9_': [None, 'mves_bs_0.9_it20'],\n",
    "    #'ensemble13_init_train_20/o_pdts_ucb_': [None, 'pdts_it20'],\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_1_minhsic_0.05_bs_0_fill_pdts_': [None, 'mves_div_1_bs_0_it20'],\n",
    "    #'ensemble13_init_train_20/o_er_pdts_ucb_div_5_': [None, 'er_pdts_div_5_it20'],\n",
    "    #'ensemble13_init_train_10/o_info_mves_div_5_minhsic_0.05_bs_0_fill_pdts_': [None, 'mves_bs_0_it10_fp'],\n",
    "    #'ensemble13_init_train_10/o_pdts_ucb_': [None, 'pdts_it10'],\n",
    "    #'ensemble13/o_pdts_ucb_': [None, 'pdts'],\n",
    "    'ensemble13/o_info_pdts_cond_div_2_fp_': [None, 'pdts_cond_fp'],\n",
    "    #'ensemble13/o_info_mves_div_5_fp_': [None, 'mves_fp'],\n",
    "    #'ensemble13/o_pdts_ucb_rand_rdiv_1_': [None, 'pdts_rand_rdiv_1'],\n",
    "    #'ensemble13/o_none_ucb_rand_rdiv_1_': [None, 'ucb_rand_rdiv_1'],\n",
    "    #'ensemble13/o_none_ucb_0.9_': [None, 'bs_0.9'],\n",
    "    #'ensemble13/o_info_mves_div_5_minhsic_0.05_bs_0.9_': [None, 'mves_bs_0.9'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ensemble13/o_info_pdts_cond_div_2_fp_\n",
      "reading sample 1\n",
      "reading sample 2\n",
      "reading sample 3\n",
      "reading sample 4\n",
      "reading sample 5\n",
      "reading sample 6\n",
      "reading sample 7\n",
      "reading sample 8\n",
      "reading sample 9\n",
      "reading sample 10\n",
      "reading sample 11\n",
      "reading sample 12\n",
      "reading sample 13\n",
      "reading sample 14\n",
      "reading sample 15\n",
      "reading sample 16\n",
      "reading sample 17\n",
      "reading sample 18\n",
      "reading sample 19\n",
      "reading sample 20\n"
     ]
    }
   ],
   "source": [
    "for k in to_read:\n",
    "    arrs[k] = to_read[k]\n",
    "for experiment in to_read:\n",
    "    print('reading', experiment)\n",
    "    arrs[experiment][0] = cs.get_data(exp_folder, experiment, batches, num_samples=20, mode=\"bayes_opt\")\n",
    "    #cs.get_data(exp_folder, experiment, batches, num_samples=20, mode=\"bayes_opt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_eval = [\n",
    "    #'ensemble7/o_none_ucb_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_maxvar_g000510204080_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_maxinvar_g000510204080_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_maxinoutvar_g000510204080_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_dataseed_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_invar_g000510204080_dataseed_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_maxvar_g000510204080_dataseed_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_inoutvar_g000510204080_dataseed_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_maxvar_inverse_g000510204080_',\n",
    "    #'ensemble7/o_kriging_believer_kb_modelseed_',\n",
    "    #'ensemble7/o_empirical_kb_ucb_weighted_0.5_div_10_modelseed_',\n",
    "    #'ensemble7/o_empirical_kb_ucb_weighted_mean_0.5_div_10_modelseed_',\n",
    "    #'ensemble7/o_kb_dataseed_modelseed_',\n",
    "    #'ensemble10/o_kb_dataseed_modelseed_',\n",
    "    #'ensemble10/o_empirical_kb_ucb_weighted_0.5_div_10_dataseed_modelseed_',\n",
    "    #'ensemble11/o_kb_dataseed_modelseed_',\n",
    "    #'ensemble11/o_empirical_kb_ucb_weighted_0.5_div_10_dataseed_modelseed_',\n",
    "    #'ensemble11/o_kb_malaria_dataseed_modelseed_',\n",
    "    #'ensemble11/o_empirical_kb_malaria_ucb_weighted_0.5_div_10_dataseed_modelseed_',\n",
    "    #'ensemble12/o_none_ucb_',\n",
    "    #'ensemble12/o_none_ucb_maxinvar_g000510204080_',\n",
    "    #'ensemble12/o_none_ucb_maxvar_g000510204080_',\n",
    "    #'ensemble12/o_none_ucb_maxvar_id_g000510204080_',\n",
    "    'ensemble13/o_none_ucb_',\n",
    "    'ensemble13/o_pdts_ucb_',\n",
    "    'ensemble13/o_info_pdts_cond_div_2_fp_',\n",
    "    'ensemble13/o_info_mves_div_5_fp_',\n",
    "    'ensemble13/o_pdts_ucb_rand_rdiv_1_',\n",
    "    'ensemble13/o_none_ucb_rand_rdiv_1_',\n",
    "    #'ensemble13/o_info_mves_div_5_minhsic_1_',\n",
    "    'ensemble13/o_pdts_ucb_rand_randdiv_3_',\n",
    "    'ensemble13/o_info_mves_div_5_minhsic_0.05_bs_0_',\n",
    "    \n",
    "    #'ensemble13_init_train_20/o_none_ucb_',\n",
    "    #'ensemble13_init_train_20/o_none_ucb_rand_randdiv_1_',\n",
    "    #'ensemble13_init_train_20/o_none_ucb_rand_randdiv_2_',\n",
    "    #'ensemble13_init_train_20/o_none_ucb_rand_randdiv_3_',\n",
    "    #'ensemble13_init_train_20/o_ei_ucb_',\n",
    "    #'ensemble13_init_train_20/o_pdts_ucb_',\n",
    "    #'ensemble13_init_train_20/o_pdts_ucb_rand_div_5_',\n",
    "    #'ensemble13_init_train_20/o_pdts_ucb_rand_div_3_',\n",
    "    #'ensemble13_init_train_20/o_er_pdts_ucb_div_5_',\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_5_minhsic_0.05_bs_0_',\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_5_minhsic_0.05_bs_0.9_',\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_5_minhsic_0.05_bs_0_fill_pdts_',\n",
    "    #'ensemble13_init_train_20/o_info_rand_mves_div_5_fp_randdiv_3_',\n",
    "    #'ensemble13_init_train_20/o_info_rand_mves_div_5_fucb_randdiv_3_',\n",
    "    #'ensemble13_init_train_20/o_info_rand_mves_div_5_randdiv_1_',\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_5_minhsic_0.0_bs_0_fill_pdts_',\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_1_minhsic_0.05_bs_0_fill_pdts_',\n",
    "    #'ensemble13_init_train_10/o_info_mves_div_5_minhsic_0.05_bs_0_fill_pdts_',\n",
    "    #'ensemble13/o_info_mves_div_5_minhsic_0.05_bs_0.9_',\n",
    "    #'ensemble13/o_info_mves_div_5_minhsic_0.05_bs_0.95_',\n",
    "    #'ensemble13/o_none_ucb_0.9_',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_data_extractor = lambda x, filename : x['idx_frac'][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ack_rel_opt_val_data_extractor = lambda x, filename : x['ack_rel_opt_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_rmse_fn = lambda x, filename : x['logging'][1]['train']['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ir_regret_fn(x, filename): \n",
    "    temp = x['ir_batch_cur_idx'].numpy().tolist()\n",
    "    temp2 = set(x['ack_idx'].numpy().tolist())\n",
    "    temp3 = None\n",
    "    for k in temp[::-1]:\n",
    "        if k not in temp2:\n",
    "            break\n",
    "    return np.exp(max(tf_labels[filename][k], tf_labels[filename][x['ack_idx']].max()))\n",
    "\n",
    "def ack_regret_fn(x, filename): \n",
    "    return np.exp(max(tf_labels[filename][x['ack_idx']].max(), tf_labels[filename][x['idx_at_each_iter'][0]].max()))\n",
    "    #return np.exp(tf_labels[filename][x['ack_idx']].max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing pdts pdts_cond_fp\n",
      "combined pval: nan vs nan\n",
      "count: 0/0\n"
     ]
    }
   ],
   "source": [
    "cs.prop_test(20, \n",
    "             filenames,\n",
    "             idx_data_extractor,\n",
    "             #ack_rel_opt_val_data_extractor, \n",
    "             arrs, \n",
    "             [to_eval[1], to_eval[2]],\n",
    "             14, \n",
    "             pval_threshold=.5,\n",
    "             paired_test=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing pdts pdts_cond_fp\n",
      "CRX_E80A_R1_8mers.txt 0.18467542651991772 256524.2 273831.28 1 \t (std: 45040.78906 37841.54297, #n: 20 20)\n",
      "OVOL2_D228E_R1_8mers.txt 0.15967378238118082 122091.36 112546.086 0 \t (std: 27837.40625 6562.03613, #n: 20 20)\n",
      "SIX6_H141N_R1_8mers.txt 0.1175479368230219 122484.625 115578.73 0 \t (std: 18219.81250 4739.90869, #n: 20 20)\n",
      "combined pval: 0.09339 vs 0.18468\n",
      "count: 1/3\n"
     ]
    }
   ],
   "source": [
    "cs.prop_test(10, \n",
    "             filenames, \n",
    "             ack_regret_fn,\n",
    "             #ack_rel_opt_val_data_extractor,\n",
    "             arrs,\n",
    "             [to_eval[1], to_eval[2]],\n",
    "             14,\n",
    "             pval_threshold=.2,\n",
    "             paired_test=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs.prop_test(20, \n",
    "             filenames, \n",
    "             ir_regret_fn, \n",
    "             arrs, \n",
    "             [to_eval[3], to_eval[5]], \n",
    "             14,\n",
    "             pval_threshold=.5,\n",
    "             paired_test=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs.uniform_baseline(\n",
    "    3,\n",
    "    tf_labels,\n",
    "    20, \n",
    "    filenames, \n",
    "    ack_regret_fn, \n",
    "    #ack_rel_opt_val_data_extractor,\n",
    "    arrs,\n",
    "    to_eval[5], \n",
    "    14, \n",
    "    pval_threshold=1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs.prop_test(100, \n",
    "             filenames, \n",
    "             idx_data_extractor, \n",
    "             arrs, \n",
    "             [to_eval[-2], to_eval[-1]], \n",
    "             9,\n",
    "             pval_threshold=0.2,\n",
    "             paired_test=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs.prop_test(100, filenames, ir_regret_fn, arrs, [to_eval[-2], to_eval[-1]], 9, pval_threshold=0.2, paired_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs.prop_test(100, filenames, ack_regret_fn, arrs, [to_eval[-2], to_eval[-1]], 9, pval_threshold=1.4, paired_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs.prop_test(200, \n",
    "             filenames, \n",
    "             idx_data_extractor, \n",
    "             arrs, \n",
    "             [to_eval[-2], to_eval[-1]], \n",
    "             29, \n",
    "             pval_threshold=1,\n",
    "             paired_test=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs.prop_test(200, filenames, ack_rel_opt_val_data_extractor, arrs, [to_eval[-2], to_eval[-1]], 29, pval_threshold=1.4, paired_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_eval = [\n",
    "    #'ensemble7/o_none_ucb_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_ucb_step_0.1_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_maxvar_g000510204080_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_maxinoutvar_g000510204080_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_maxinvar_g000510204080_modelseed_',\n",
    "    \n",
    "    #'ensemble7/o_none_ucb_dataseed_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_invar_g000510204080_dataseed_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_maxvar_g000510204080_dataseed_modelseed_',\n",
    "    #'ensemble7/o_none_ucb_maxvar_inverse_g000510204080_',\n",
    "    \n",
    "    #'ensemble7/o_none_ucb_inoutvar_g000510204080_dataseed_modelseed_',\n",
    "    #'ensemble7/o_kriging_believer_kb_modelseed_',\n",
    "    #'ensemble7/o_empirical_kb_ucb_weighted_0.5_div_10_modelseed_',\n",
    "    #'ensemble7/o_empirical_kb_ucb_weighted_mean_0.5_div_10_modelseed_',\n",
    "    #'ensemble7/o_empirical_kb_div_3_modelseed_',\n",
    "    #'ensemble7/o_empirical_kb_ucb_weighted_div_10_modelseed_',\n",
    "    #'ensemble7/o_kb_dataseed_modelseed_',\n",
    "    #'ensemble7/o_empirical_kb_ucb_weighted_div_10_dataseed_modelseed_',\n",
    "    #'ensemble10/o_kb_dataseed_modelseed_',\n",
    "    #'ensemble10/o_empirical_kb_ucb_weighted_0.5_div_10_dataseed_modelseed_',\n",
    "    #'ensemble11/o_kb_dataseed_modelseed_',\n",
    "    #'ensemble11/o_empirical_kb_ucb_weighted_0.5_div_10_dataseed_modelseed_',\n",
    "    #'ensemble11/o_kb_malaria_dataseed_modelseed_',\n",
    "    #'ensemble11/o_empirical_kb_malaria_ucb_weighted_0.5_div_10_dataseed_modelseed_',\n",
    "    \n",
    "    #'ensemble12/o_none_ucb_',\n",
    "    #'ensemble13/o_info_mves_div_5_minhsic_1_',\n",
    "    'ensemble13/o_none_ucb_',\n",
    "    #'ensemble13/o_info_mves_div_5_minhsic_0.05_bs_0.95_',\n",
    "    #'ensemble13/o_info_mves_div_5_minhsic_0.05_bs_0.9_',\n",
    "    #'ensemble13/o_info_mves_div_5_minhsic_0.05_bs_0_',\n",
    "    #'ensemble13/o_none_ucb_0.9_',\n",
    "    'ensemble13/o_pdts_ucb_',\n",
    "    #'ensemble13_init_train_20/o_none_ucb_',\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_5_minhsic_0.05_bs_0_',\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_5_minhsic_0.05_bs_0_fill_pdts_',\n",
    "    #'ensemble13_init_train_20/o_info_mves_div_5_minhsic_0.05_bs_0.9_',\n",
    "    #'ensemble13_init_train_20/o_pdts_ucb_',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH SIZE 10\n",
      "HESX1_E149K_R1_8mers.txt\n",
      "e13: 0.160671 0.067275 0.037853 0.020185 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.178049 0.068187 0.037747 0.020155 ;   0.00 val_nll ; 20 samples\n",
      "EGR2_D383Y_R1_8mers.txt\n",
      "e13: 0.009756 0.006934 0.008179 0.009561 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.021799 0.011861 0.010292 0.009804 ;   0.00 val_nll ; 20 samples\n",
      "BCL6_H676Y_R1_8mers.txt\n",
      "e13: 0.212500 0.076825 0.041502 0.021037 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.208689 0.077281 0.041821 0.021113 ;   0.00 val_nll ; 20 samples\n",
      "ARX_L343Q_R1_8mers.txt\n",
      "e13: 0.077439 0.041119 0.026604 0.016644 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.082774 0.041819 0.028109 0.017085 ;   0.00 val_nll ; 20 samples\n",
      "CRX_E80A_R1_8mers.txt\n",
      "e13: 0.045122 0.051582 0.034722 0.020049 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.048628 0.052190 0.035041 0.020216 ;   0.00 val_nll ; 20 samples\n",
      "pdts_cond_fp: 0.045732 0.051247 0.034372 0.020018 ;   0.00 val_nll ; 20 samples\n",
      "ESX1_K193R_R1_8mers.txt\n",
      "e13: 0.213720 0.072567 0.040164 0.021082 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.207165 0.073449 0.040073 0.021006 ;   0.00 val_nll ; 20 samples\n",
      "FOXC1_F112S_R1_8mers.txt\n",
      "e13: 0.120732 0.057360 0.034752 0.020003 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.115854 0.054684 0.034038 0.019843 ;   0.00 val_nll ; 20 samples\n",
      "GFI1B_A204T_R1_8mers.txt\n",
      "e13: 0.031707 0.030596 0.024719 0.017282 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.029726 0.030201 0.024673 0.017442 ;   0.00 val_nll ; 20 samples\n",
      "GFI1_L400F_R1_8mers.txt\n",
      "e13: 0.014939 0.059854 0.038705 0.021067 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.015701 0.060401 0.038872 0.021029 ;   0.00 val_nll ; 20 samples\n",
      "HOXC4_N178S_R1_8mers.txt\n",
      "e13: 0.209451 0.078041 0.041715 0.021204 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.204116 0.077403 0.041548 0.021204 ;   0.00 val_nll ; 20 samples\n",
      "HOXD13_I322L_R1_8mers.txt\n",
      "e13: 0.178659 0.078102 0.041289 0.021052 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.178049 0.078406 0.041487 0.021143 ;   0.00 val_nll ; 20 samples\n",
      "ISX_R83Q_R1_8mers.txt\n",
      "e13: 0.206098 0.072749 0.040316 0.020945 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.212805 0.073449 0.040499 0.020961 ;   0.00 val_nll ; 20 samples\n",
      "KLF11_R402Q_R1_8mers.txt\n",
      "e13: 0.106098 0.052190 0.032563 0.018909 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.133841 0.056904 0.033749 0.019251 ;   0.00 val_nll ; 20 samples\n",
      "KLF1_E325K_R1_8mers.txt\n",
      "e13: 0.180183 0.050487 0.028002 0.015443 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.130183 0.039781 0.023259 0.013794 ;   0.00 val_nll ; 20 samples\n",
      "pdts_cond_fp: 0.148628 0.044161 0.025707 0.014881 ;   0.00 val_nll ; 20 samples\n",
      "MSX2_P148H_R1_8mers.txt\n",
      "e13: 0.218293 0.075730 0.041654 0.021249 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.218902 0.075426 0.041608 0.021249 ;   0.00 val_nll ; 20 samples\n",
      "NKX2-5_K183E_R1_8mers.txt\n",
      "e13: 0.191159 0.078771 0.042049 0.021234 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.188262 0.078467 0.042125 0.021242 ;   0.00 val_nll ; 20 samples\n",
      "NR1H4_C144R_R1_8mers.txt\n",
      "e13: 0.115549 0.058151 0.038157 0.020809 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.116311 0.058273 0.038340 0.020725 ;   0.00 val_nll ; 20 samples\n",
      "NR2E3_G56R_R1_8mers.txt\n",
      "e13: 0.056098 0.039842 0.029340 0.018589 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.059604 0.041484 0.030009 0.018924 ;   0.00 val_nll ; 20 samples\n",
      "OVOL2_D228E_R1_8mers.txt\n",
      "e13: 0.000000 0.042214 0.035877 0.020885 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.001220 0.041180 0.034965 0.020733 ;   0.00 val_nll ; 20 samples\n",
      "PAX3_G48R_R1_8mers.txt\n",
      "e13: 0.107012 0.054258 0.032411 0.018833 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.110366 0.055870 0.032852 0.018612 ;   0.00 val_nll ; 20 samples\n",
      "PAX4_R183C_R1_8mers.txt\n",
      "e13: 0.162195 0.064051 0.037914 0.020581 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.159756 0.063108 0.037945 0.020588 ;   0.00 val_nll ; 20 samples\n",
      "PAX6_A79E_R1_8mers.txt\n",
      "e13: 0.012500 0.008090 0.006963 0.006080 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.011280 0.008577 0.007631 0.006300 ;   0.00 val_nll ; 20 samples\n",
      "PAX7_P112L_R1_8mers.txt\n",
      "e13: 0.124390 0.052859 0.034965 0.019547 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.126829 0.052129 0.034418 0.019387 ;   0.00 val_nll ; 20 samples\n",
      "PBX4_R215Q_R1_8mers.txt\n",
      "e13: 0.128659 0.057786 0.036151 0.020368 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.122256 0.057543 0.036136 0.020360 ;   0.00 val_nll ; 20 samples\n",
      "PHOX2B_Q143R_R1_8mers.txt\n",
      "e13: 0.118598 0.052920 0.033019 0.018909 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.128049 0.054288 0.032928 0.018909 ;   0.00 val_nll ; 20 samples\n",
      "PITX2_L100Q_R1_8mers.txt\n",
      "e13: 0.059146 0.052676 0.034965 0.020185 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.079726 0.055870 0.035908 0.020368 ;   0.00 val_nll ; 20 samples\n",
      "POU3F4_A237G_R1_8mers.txt\n",
      "e13: 0.251220 0.081509 0.042566 0.021280 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.252896 0.081813 0.042475 0.021280 ;   0.00 val_nll ; 20 samples\n",
      "pdts_cond_fp: 0.250610 0.081813 0.042460 0.021280 ;   0.00 val_nll ; 20 samples\n",
      "POU4F3_K277R_R1_8mers.txt\n",
      "e13: 0.221341 0.080414 0.041897 0.021280 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.240396 0.080991 0.042049 0.021280 ;   0.00 val_nll ; 20 samples\n",
      "POU6F2_E639K_R1_8mers.txt\n",
      "e13: 0.136585 0.065024 0.037033 0.020109 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.150457 0.065937 0.037990 0.020178 ;   0.00 val_nll ; 20 samples\n",
      "PROP1_R112Q_R1_8mers.txt\n",
      "e13: 0.230183 0.075487 0.040772 0.020915 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.224695 0.075791 0.041061 0.020923 ;   0.00 val_nll ; 20 samples\n",
      "SIX6_H141N_R1_8mers.txt\n",
      "e13: 0.100610 0.055474 0.035482 0.020307 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.107012 0.056478 0.035725 0.020216 ;   0.00 val_nll ; 20 samples\n",
      "SNAI2_D119E_R1_8mers.txt\n",
      "e13: 0.164939 0.077798 0.041836 0.021265 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.160671 0.076338 0.041593 0.021249 ;   0.00 val_nll ; 20 samples\n",
      "VAX2_L139M_R1_8mers.txt\n",
      "e13: 0.190854 0.072019 0.040103 0.021006 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.200000 0.074118 0.041016 0.021196 ;   0.00 val_nll ; 20 samples\n",
      "VENTX_E101K_R1_8mers.txt\n",
      "e13: 0.090549 0.053528 0.033323 0.019380 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.091463 0.050791 0.031636 0.018658 ;   0.00 val_nll ; 20 samples\n",
      "VSX1_G160D_R1_8mers.txt\n",
      "e13: 0.208841 0.073662 0.040711 0.021158 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.206555 0.072901 0.040225 0.021097 ;   0.00 val_nll ; 20 samples\n",
      "WT1_F392L_R1_8mers.txt\n",
      "e13: 0.162805 0.067336 0.040438 0.021173 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.162500 0.067609 0.040605 0.021166 ;   0.00 val_nll ; 20 samples\n",
      "ZNF200_H322Y_R1_8mers.txt\n",
      "e13: 0.059146 0.036983 0.026178 0.016872 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.057012 0.035614 0.026026 0.016849 ;   0.00 val_nll ; 20 samples\n",
      "ZNF655_E327G_R1_8mers.txt\n",
      "e13: 0.016159 0.025061 0.023047 0.017723 ;   0.00 val_nll ; 10 samples\n",
      "pdts: 0.016159 0.026460 0.023518 0.017632 ;   0.00 val_nll ; 20 samples\n"
     ]
    }
   ],
   "source": [
    "ack_iter = 14\n",
    "for batch_size in [10]:\n",
    "    print(\"BATCH SIZE\", batch_size)\n",
    "    for filename in filenames:\n",
    "        filename_printed = False\n",
    "        for experiment in to_eval:\n",
    "            if len(arrs[experiment][0]) == 0:\n",
    "                continue\n",
    "            idx_frac = None\n",
    "            num_used = 0\n",
    "            val_nll = 0\n",
    "            try:\n",
    "                for stats in arrs[experiment][0]:\n",
    "                    if filename not in stats:\n",
    "                        continue\n",
    "                    if batch_size not in stats[filename]:\n",
    "                        continue\n",
    "                    if len(stats[filename][batch_size]) <= ack_iter:\n",
    "                        continue\n",
    "                    num_used += 1\n",
    "                    mean = 0\n",
    "                    #for i in range(len(stats[filename][batch_size])):\n",
    "                        #mean += stats[filename][batch_size][i]['logging'][1]['best']['nll']\n",
    "                    if len(stats[filename][batch_size]) > 0:\n",
    "                        mean /= (len(stats[filename][batch_size]))\n",
    "                    #val_nll += stats[filename][batch_size][0]['logging'][1]['best']['nll']\n",
    "                    val_nll += mean\n",
    "                    if idx_frac is None:\n",
    "                        idx_frac = stats[filename][batch_size][ack_iter]['idx_frac']\n",
    "                        #idx_frac = tf_labels[filename][stats[filename][batch_size][ack_iter]['ir_batch_cur_idx'][-1]]\n",
    "                        #idx_frac = stats[filename][batch_size][ack_iter]['corr_stats'][1]\n",
    "                    else:\n",
    "                        idx_frac = idx_frac + stats[filename][batch_size][ack_iter]['idx_frac']\n",
    "                        #idx_frac = torch.max(idx_frac, stats[filename][batch_size][ack_iter]['idx_frac'])\n",
    "                        #idx_frac = idx_frac + tf_labels[filename][stats[filename][batch_size][ack_iter]['ir_batch_cur_idx'][-1]]\n",
    "                        #idx_frac = idx_frac + stats[filename][batch_size][ack_iter]['corr_stats'][1]\n",
    "                if num_used > 0:\n",
    "                    if not filename_printed:\n",
    "                        print(filename)\n",
    "                        filename_printed = True\n",
    "                    idx_frac = idx_frac/num_used\n",
    "                    #idx_frac = idx_frac.numpy()\n",
    "                    print(arrs[experiment][1] + \":\", \" \".join((\"{:6.6f}\".format(k) for k in idx_frac)), \";\", \"{:6.2f}\".format(val_nll/num_used), \"val_nll ;\", str(num_used), \"samples\")\n",
    "                    #print(arrs[experiment][1] + \":\", str(idx_frac), \";\", \"{:6.2f}\".format(val_nll/num_used), \"val_nll ;\", str(num_used), \"samples\")\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collect_stats as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cs.plot_data_vs_ack_iter(\n",
    "    20,\n",
    "    filenames,\n",
    "    'avg_seeds',\n",
    "    'relative optimal value',\n",
    "    #ack_regret_fn,\n",
    "    ack_rel_opt_val_data_extractor,\n",
    "    14,\n",
    "    arrs,\n",
    "    to_eval,\n",
    "    legend_loc=3,\n",
    "    figsize=(6, 4),\n",
    "    num_samples_label=True,\n",
    "    save_path='/cluster/sj1/bb_opt/plots',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs.plot_data_vs_ack_iter(\n",
    "    10,\n",
    "    filenames[0:15],\n",
    "    'avg_seeds',\n",
    "    'gamma',\n",
    "    lambda x : x['best_gamma'] if x['best_gamma'] is not None else 0,\n",
    "    30,\n",
    "    arrs,\n",
    "    to_eval,\n",
    "    legend_loc=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ack_iter = 0\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    for batch_size in batches:\n",
    "        for experiment in to_eval:\n",
    "            best_value = 0\n",
    "            num_used = 0\n",
    "            for stats in arrs[experiment][0]:\n",
    "                if filename not in stats:\n",
    "                    continue\n",
    "                if batch_size not in stats[filename]:\n",
    "                    continue\n",
    "                num_used += 1\n",
    "                best_value += stats[filename][batch_size][ack_iter]['logging'][9].item()\n",
    "            if num_used > 0:\n",
    "                best_value = best_value/num_used\n",
    "                print(arrs[experiment][1] + \":\", best_value, \";\", str(num_used), \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_properties = [\n",
    "    'test_log_prob',\n",
    "    'test_mse',\n",
    "    'test_kt_corr',\n",
    "    'test_std_list',\n",
    "    'test_mse_std_corr'\n",
    "]\n",
    "\n",
    "avg = True\n",
    "\n",
    "for prop in test_properties[1:2]:\n",
    "    for filename in filenames[0:1]:\n",
    "        print(filename)\n",
    "        for batch_size in batches:\n",
    "            for experiment in arrs:\n",
    "                plt.figure(figsize=(15, 4))\n",
    "                plt.subplot(121)\n",
    "                prop_list = np.array([0.]*num_acks)\n",
    "                num_used = 0\n",
    "                for stats in arrs[experiment][0]:\n",
    "                    if filename not in stats:\n",
    "                        continue\n",
    "                    if batch_size not in stats[filename]:\n",
    "                        continue\n",
    "                    if len(stats[filename][batch_size]) < num_acks:\n",
    "                        continue\n",
    "                    num_used += 1\n",
    "                    if avg:\n",
    "                        prop_list += np.array([stats[filename][batch_size][i][prop][0].item() for i in range(num_acks)])\n",
    "                    else:\n",
    "                        prop_list = [stats[filename][batch_size][i][prop][0].item() for i in range(num_acks)]\n",
    "                    if not avg:\n",
    "                        plt.plot(prop_list)\n",
    "                if avg:\n",
    "                    plt.plot(prop_list/num_used)\n",
    "                plt.title(arrs[experiment][1] + \"; \" + prop + \"; all\")\n",
    "                plt.subplot(122)\n",
    "                prop_list = np.array([0.]*num_acks)\n",
    "                num_used = 0\n",
    "                for stats in arrs[experiment][0]:\n",
    "                    if filename not in stats:\n",
    "                        continue\n",
    "                    if batch_size not in stats[filename]:\n",
    "                        continue\n",
    "                    if len(stats[filename][batch_size]) < num_acks:\n",
    "                        continue\n",
    "                    num_used += 1\n",
    "                    if avg:\n",
    "                        prop_list += np.array([stats[filename][batch_size][i][prop][1].item() for i in range(num_acks)])\n",
    "                    else:\n",
    "                        prop_list = [stats[filename][batch_size][i][prop][1].item() for i in range(num_acks)]\n",
    "                    if not avg:\n",
    "                        plt.plot(prop_list)\n",
    "                if avg:\n",
    "                    plt.plot(prop_list/num_used)\n",
    "                plt.title(arrs[experiment][1] + \"; \" + prop + \"; top 10%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ack_iter = 0\n",
    "for filename in filenames[2:3]:\n",
    "    print(filename)\n",
    "    for batch_size in batches:\n",
    "        for experiment in arrs:\n",
    "            plt.figure(figsize=(15, 4))\n",
    "            for stats in arrs[experiment][0]:\n",
    "                #for i in range(num_acks):\n",
    "                if filename not in stats:\n",
    "                    continue\n",
    "                if batch_size not in stats[filename]:\n",
    "                    continue\n",
    "                prop_list = stats[filename][batch_size][ack_iter]['logging'][-1].numpy()\n",
    "                plt.plot(prop_list)\n",
    "                plt.title(arrs[experiment][1] + \"; \" + str(ack_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_eval = [\n",
    "    #'top_val_none_ucb_g0.0_',\n",
    "    'top_val_none_ucb_maxstd_g01051020_',\n",
    "    'top_val_none_ucb_g0.0_200epochs_last_',\n",
    "    #'top_val_none_ucb_maxvar_g01051020_',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ack_iter = 1\n",
    "for filename in filenames[:3]:\n",
    "    print(filename)\n",
    "    for batch_size in batches:\n",
    "        for experiment in to_eval:\n",
    "            plt.figure(figsize=(15, 4))\n",
    "            for stats in arrs[experiment][0]:\n",
    "                #for i in range(num_acks):\n",
    "                if filename not in stats:\n",
    "                    continue\n",
    "                if batch_size not in stats[filename]:\n",
    "                    continue\n",
    "                #prop_list = stats[filename][batch_size][ack_iter]['logging'][5].numpy()\n",
    "                prop_list = stats[filename][batch_size][ack_iter]['best_gamma']\n",
    "                plt.plot(prop_list)\n",
    "                plt.title(arrs[experiment][1] + \"; \" + str(ack_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_properties = [\n",
    "    'test_log_prob',\n",
    "    'test_mse',\n",
    "    'test_kt_corr',\n",
    "    'test_std_list',\n",
    "    'test_mse_std_corr'\n",
    "]\n",
    "\n",
    "ack_iter = -1\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    for batch_size in [10]:\n",
    "        for experiment in to_eval:\n",
    "            m = None\n",
    "            num_used = 0\n",
    "            for stats in arrs[experiment][0]:\n",
    "                #for i in range(num_acks):\n",
    "                if filename not in stats:\n",
    "                    continue\n",
    "                if batch_size not in stats[filename]:\n",
    "                    continue\n",
    "                num_used += 1\n",
    "                #m += stats[filename][batch_size][ack_iter]['test_std_list'][0].item()\n",
    "                m2 = np.array([\n",
    "                    np.exp(stats[filename][batch_size][ack_iter]['ack_labels'].max()-tf_max[filename]),\n",
    "                    #stats[filename][batch_size][ack_iter]['test_std_list'][0].item(),\n",
    "                    #stats[filename][batch_size][ack_iter]['test_std_list'][1].item(),\n",
    "                    #stats[filename][batch_size][ack_iter]['test_std_list'][2].item()\n",
    "                ])\n",
    "                if m is None:\n",
    "                    m = m2\n",
    "                else:\n",
    "                    m += m2\n",
    "            if num_used > 0:\n",
    "                print(arrs[experiment][1], \":\", m/num_used, \";\", num_used, \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_labels = 32897"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_eval = [\n",
    "    'take_log_none_ucb_c1.0_g0.0_',\n",
    "    #'take_log_none_ucb_c2.0_g0.0_',\n",
    "    'take_log_none_ucb_c1.0_g5.0_',\n",
    "    'take_log_none_ucb_c1.0_g10.0_',\n",
    "    'take_log_none_ucb_c1.0_g20.0_',\n",
    "]\n",
    "\n",
    "to_eval = [\n",
    "    'take_log_none_ucb_num_acks_30_c1.0_g0.0_',\n",
    "    'take_log_none_ucb_num_acks_30_c1.0_g5.0_',\n",
    "    'take_log_none_ucb_num_acks_30_c1.0_g10.0_',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_acks = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_eval = {\n",
    "    'take_log_none_ucb_num_acks_30_c1.0_g0.0_': 'Normal',\n",
    "    'take_log_none_ucb_num_acks_30_c1.0_maxvar_' : 'MOD',\n",
    "    'take_log_none_ucb_num_acks_30_c1.0_mincorr_' : 'MOD2',\n",
    "}\n",
    "\n",
    "to_eval = {\n",
    "    'take_log_none_ucb_ntest' : 'Normal',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_eval = [\n",
    "    #'top_val_none_ucb_g0.0_',\n",
    "    'top_val_none_ucb_g0.0_modelseed',\n",
    "    #'top_val_none_ucb_maxstd_g01051020_',\n",
    "    #'top_val_none_ucb_g0.0_200epochs_last_',\n",
    "    #'top_val_none_ucb_maxvar_g01051020_',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "avg = True\n",
    "num_acks = 10\n",
    "\n",
    "for batch_size in batches:\n",
    "    for filename in filenames:\n",
    "        if avg:\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            legend = []\n",
    "        for experiment in to_eval:\n",
    "            if not avg:\n",
    "                plt.figure(figsize=(15, 4))\n",
    "            prop_list = []\n",
    "            num_used = 0\n",
    "            for stats in arrs[experiment][0]:\n",
    "                if filename not in stats:\n",
    "                    continue\n",
    "                if batch_size not in stats[filename]:\n",
    "                    continue\n",
    "                if len(stats[filename][batch_size]) < num_acks:\n",
    "                    continue\n",
    "                num_used += 1\n",
    "                if avg:\n",
    "                    #prop_list += [np.array([np.exp(stats[filename][batch_size][ack_iter]['ack_labels'].max()-tf_max[filename]) for ack_iter in range(num_acks)])]\n",
    "                    #prop_list += [np.array([(stats[filename][batch_size][ack_iter]['idx_frac'][0]) for ack_iter in range(num_acks)])]\n",
    "                    #prop_list += [np.array([(stats[filename][batch_size][ack_iter]['corr_stats'][0][-4]) for ack_iter in range(num_acks)])]\n",
    "                    prop_list += [np.array([(stats[filename][batch_size][ack_iter]['logging'][0][8]) for ack_iter in range(num_acks)])]\n",
    "                else:\n",
    "                    prop_list = [(stats[filename][batch_size][ack_iter]['ack_labels'].max()) for ack_iter in range(num_acks)]\n",
    "                    prop_list = [np.array([(stats[filename][batch_size][ack_iter]['corr_stats'][0][-4]) for ack_iter in range(num_acks)])]\n",
    "                if not avg:\n",
    "                    plt.plot(prop_list)\n",
    "            if avg and num_used > 0:\n",
    "                prop_list = np.stack(prop_list, axis=0)\n",
    "                plt.plot(np.median(prop_list, axis=0))\n",
    "                legend += [arrs[experiment][1]]\n",
    "            elif not avg:\n",
    "                plt.title(arrs[experiment][1] + \"; \" + str(batch_size) + \"; all\")\n",
    "        if avg:\n",
    "            plt.legend(legend)\n",
    "            plt.xlabel('Acquisition Iteration')\n",
    "            plt.ylabel('Relative optimal value')\n",
    "            #plt.title(filename + \"; \" + str(batch_size) + \"; all\")\n",
    "            plt.title(filename.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "avg = True\n",
    "\n",
    "for batch_size in batches:\n",
    "    for filename in filenames:\n",
    "        if avg:\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            legend = []\n",
    "        for experiment in to_eval:\n",
    "            if not avg:\n",
    "                plt.figure(figsize=(15, 4))\n",
    "                \n",
    "            for prop_i in [5, 6]:\n",
    "                prop_list = []\n",
    "                num_used = 0\n",
    "                for stats in arrs[experiment][0]:\n",
    "                    if filename not in stats:\n",
    "                        continue\n",
    "                    if batch_size not in stats[filename]:\n",
    "                        continue\n",
    "                    if len(stats[filename][batch_size]) < num_acks:\n",
    "                        continue\n",
    "                    num_used += 1\n",
    "                    if avg:\n",
    "                        #prop_list += [np.array([np.exp(stats[filename][batch_size][ack_iter]['ack_labels'].max()-tf_max[filename]) for ack_iter in range(num_acks)])]\n",
    "                        #prop_list += [np.array([(stats[filename][batch_size][ack_iter]['idx_frac'][0]) for ack_iter in range(num_acks)])]\n",
    "                        #prop_list += [np.array([(stats[filename][batch_size][ack_iter]['corr_stats'][1][prop_i].item()) for ack_iter in range(num_acks)])]\n",
    "                        prop_list += [np.array([(stats[filename][batch_size][ack_iter]['best_gamma']) for ack_iter in range(num_acks)])]\n",
    "                    else:\n",
    "                        prop_list = [(stats[filename][batch_size][ack_iter]['ack_labels'].max()) for ack_iter in range(num_acks)]\n",
    "                        prop_list = [np.array([(stats[filename][batch_size][ack_iter]['corr_stats'][1][prop_i].item()) for ack_iter in range(num_acks)])]\n",
    "                    if not avg:\n",
    "                        plt.plot(prop_list)\n",
    "                if avg and num_used > 0:\n",
    "                    prop_list = np.stack(prop_list, axis=0)\n",
    "                    plt.plot(np.median(prop_list, axis=0))\n",
    "                    legend += [str(prop_i)]\n",
    "                elif not avg:\n",
    "                    plt.title(arrs[experiment][1] + \"; \" + str(batch_size) + \"; all\")\n",
    "        if avg:\n",
    "            plt.legend(legend)\n",
    "            plt.xlabel('Acquisition Iteration')\n",
    "            plt.ylabel('Relative optimal value')\n",
    "            #plt.title(filename + \"; \" + str(batch_size) + \"; all\")\n",
    "            plt.title(filename.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg = True\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "legend = []\n",
    "for experiment in to_eval:\n",
    "    prop_list = []\n",
    "    for batch_size in [10]:\n",
    "        for filename in filenames:\n",
    "            for stats in arrs[experiment][0]:\n",
    "                if filename not in stats:\n",
    "                    continue\n",
    "                if batch_size not in stats[filename]:\n",
    "                    continue\n",
    "                if len(stats[filename][batch_size]) < num_acks:\n",
    "                    continue\n",
    "                prop_list += [np.array([np.exp(stats[filename][batch_size][ack_iter]['ack_labels'].max()-tf_max[filename]) for ack_iter in range(num_acks)])]\n",
    "                #prop_list += [np.array([(stats[filename][batch_size][ack_iter]['idx_frac'][0]) for ack_iter in range(num_acks)])]\n",
    "    prop_list = np.stack(prop_list, axis=0)\n",
    "    plt.plot(np.median(prop_list, axis=0))\n",
    "    #legend += [arrs[experiment][1]]\n",
    "    legend += [to_eval[experiment]]\n",
    "plt.legend(legend)\n",
    "plt.xlabel('Acquisition Iteration')\n",
    "plt.ylabel('Relative optimal value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
