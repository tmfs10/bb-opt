{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_x = .7\n",
    "sigma_y = .5\n",
    "sigma_xy = .3\n",
    "cov = np.array([[sigma_x, sigma_xy], [sigma_xy, sigma_y]]) ** 2\n",
    "mu = [0, 0]\n",
    "\n",
    "n_points = 100\n",
    "\n",
    "def sample_xy():\n",
    "    x, y = np.random.multivariate_normal(mu, cov, n_points).T\n",
    "    x = x[:, None]\n",
    "    y = y[:, None]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6634354703245452"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = - 1 / 2 * np.log(1 - (sigma_xy / (sigma_x * sigma_y)) ** 2)\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6586275647284517"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "var = 0.2\n",
    "def func(x):\n",
    "    return x\n",
    "#     return np.sin(x)\n",
    "\n",
    "def sample_xy():\n",
    "#     x = np.random.normal(0, 1, [data_size, 1])\n",
    "    x = np.sign(np.random.normal(0.,1.,[data_size,1]))\n",
    "    y = func(x) + np.random.normal(0, np.sqrt(var), [data_size, 1])\n",
    "    return x, y\n",
    "\n",
    "data_size = 1000000\n",
    "x, y = sample_xy()\n",
    "p_y_x = np.exp(-(y - x) ** 2 / (2 * var))\n",
    "p_y_x_minus = np.exp(-(y + 1) ** 2 / (2 * var))\n",
    "p_y_x_plus = np.exp(-(y - 1) ** 2 / (2 * var))\n",
    "mi = np.average(np.log(p_y_x / (0.5 * p_y_x_minus + 0.5 * p_y_x_plus)))\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50 100 150 200 250 300 350 400 450 "
     ]
    }
   ],
   "source": [
    "H = 10\n",
    "n_epoch = 500\n",
    "n_points = 20000\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, H)\n",
    "        self.fc2 = nn.Linear(1, H)\n",
    "        self.fc3 = nn.Linear(H, 1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        h1 = torch.relu(self.fc1(x) + self.fc2(y))\n",
    "        h2 = self.fc3(h1)\n",
    "        return h2\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "plot_loss = []\n",
    "for epoch in range(n_epoch):\n",
    "    x_sample, y_sample = sample_xy()\n",
    "    y_shuffle = np.random.permutation(y_sample)\n",
    "    \n",
    "    x_sample = torch.tensor(x_sample, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    y_sample = torch.tensor(y_sample, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    y_shuffle = torch.tensor(y_shuffle, dtype=torch.float32, device=device, requires_grad=True)    \n",
    "    \n",
    "    pred_xy = model(x_sample, y_sample)\n",
    "    pred_x_y = model(x_sample, y_shuffle)\n",
    "\n",
    "    ret = torch.mean(pred_xy) - torch.log(torch.mean(torch.exp(pred_x_y)))\n",
    "    loss = - ret  # maximize\n",
    "    plot_loss.append(loss.item())\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(epoch, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = sample_xy()\n",
    "mi_kraskov = mi_Kraskov(xy)\n",
    "mi_lnc = mi_LNC(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f103cb5ddd8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f10141ebbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_x = np.arange(len(plot_loss))\n",
    "plot_y = np.array(plot_loss).reshape(-1,)\n",
    "\n",
    "plt.plot(plot_x, -plot_y, label=\"MINE\")\n",
    "plt.hlines(mi, plot_x.min(), plot_x.max(), label=\"True MI\")\n",
    "# plt.hlines(mi_kraskov, plot_x.min(), plot_x.max(), label=\"Kraskov\", colors=\"r\")\n",
    "# plt.hlines(mi_lnc, plot_x.min(), plot_x.max(), label=\"LNC\", colors=\"g\", linestyles=\"dashed\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN-MI and ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.special import digamma, gamma\n",
    "import numpy.random as nr\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from scipy.stats.stats import pearsonr\n",
    "import numpy.linalg as la\n",
    "from numpy.linalg import eig, inv, norm, det\n",
    "from scipy import stats\n",
    "from math import log, pi, hypot, fabs, sqrt\n",
    "\n",
    "\n",
    "def avgdigamma(points, dvec):\n",
    "    # This part finds number of neighbors in some radius in the marginal space\n",
    "    # returns expectation value of <psi(nx)>\n",
    "    N = len(points)\n",
    "    tree = cKDTree(points)\n",
    "    avg = 0.0\n",
    "    for i in range(N):\n",
    "        dist = dvec[i]\n",
    "        # subtlety, we don't include the boundary point,\n",
    "        # but we are implicitly adding 1 to kraskov def bc center point is included\n",
    "        num_points = len(tree.query_ball_point(points[i], dist - 1e-15, p=float(\"inf\")))\n",
    "        avg += digamma(num_points) / N\n",
    "    return avg\n",
    "\n",
    "\n",
    "def mi_Kraskov(X, k=5, base=np.exp(1), intens=1e-10):\n",
    "    \"\"\"\n",
    "    The mutual information estimator by Kraskov et al.\n",
    "    ith row of X represents ith dimension of the data, e.g. X = [[1.0,3.0,3.0],[0.1,1.2,5.4]], if X has two dimensions and we have three samples\n",
    "    \"\"\"\n",
    "    # adding small noise to X, e.g., x<-X+noise\n",
    "    x = []\n",
    "    for i in range(len(X)):\n",
    "        tem = []\n",
    "        for j in range(len(X[i])):\n",
    "            tem.append([X[i][j] + intens * nr.rand(1)[0]])\n",
    "        x.append(tem)\n",
    "\n",
    "    points = []\n",
    "    for j in range(len(x[0])):\n",
    "        tem = []\n",
    "        for i in range(len(x)):\n",
    "            tem.append(x[i][j][0])\n",
    "        points.append(tem)\n",
    "    tree = cKDTree(points)\n",
    "    dvec = []\n",
    "    for i in range(len(x)):\n",
    "        dvec.append([])\n",
    "    for point in points:\n",
    "        # Find k-nearest neighbors in joint space, p=inf means max norm\n",
    "        knn = tree.query(point, k + 1, p=float(\"inf\"))\n",
    "        points_knn = []\n",
    "        for i in range(len(x)):\n",
    "            dvec[i].append(float(\"-inf\"))\n",
    "            points_knn.append([])\n",
    "        for j in range(k + 1):\n",
    "            for i in range(len(x)):\n",
    "                points_knn[i].append(points[knn[1][j]][i])\n",
    "\n",
    "        # Find distances to k-nearest neighbors in each marginal space\n",
    "        for i in range(k + 1):\n",
    "            for j in range(len(x)):\n",
    "                if dvec[j][-1] < fabs(points_knn[j][i] - points_knn[j][0]):\n",
    "                    dvec[j][-1] = fabs(points_knn[j][i] - points_knn[j][0])\n",
    "\n",
    "    ret = 0.\n",
    "    for i in range(len(x)):\n",
    "        ret -= avgdigamma(x[i], dvec[i])\n",
    "    ret += (\n",
    "        digamma(k)\n",
    "        - (float(len(x)) - 1.) / float(k)\n",
    "        + (float(len(x)) - 1.) * digamma(len(x[0]))\n",
    "    )\n",
    "    return ret\n",
    "\n",
    "\n",
    "def mi_Kraskov2(x: np.ndarray, k=5, base=np.exp(1), intens=1e-10):\n",
    "    \"\"\"\n",
    "    The mutual information estimator by Kraskov et al.\n",
    "    ith row of X represents ith dimension of the data, e.g. X = [[1.0,3.0,3.0],[0.1,1.2,5.4]], if X has two dimensions and we have three samples\n",
    "    \"\"\"\n",
    "\n",
    "    n_vars, n_samples = x.shape\n",
    "\n",
    "    # adding small noise to X, e.g., x<-X+noise\n",
    "    x += intens * nr.rand(n_vars, n_samples)\n",
    "    x = x.T\n",
    "\n",
    "    tree = cKDTree(x)\n",
    "    dvec = [[] for _ in range(n_vars)]\n",
    "\n",
    "    for point in x:\n",
    "        # Find k-nearest neighbors in joint space, p=inf means max norm\n",
    "        knn = tree.query(point, k + 1, p=float(\"inf\"))\n",
    "        points_knn = []\n",
    "        for i in range(len(x)):\n",
    "            dvec[i].append(float(\"-inf\"))\n",
    "            points_knn.append([])\n",
    "        for j in range(k + 1):\n",
    "            for i in range(len(x)):\n",
    "                points_knn[i].append(points[knn[1][j]][i])\n",
    "\n",
    "        # Find distances to k-nearest neighbors in each marginal space\n",
    "        for i in range(k + 1):\n",
    "            for j in range(len(x)):\n",
    "                if dvec[j][-1] < fabs(points_knn[j][i] - points_knn[j][0]):\n",
    "                    dvec[j][-1] = fabs(points_knn[j][i] - points_knn[j][0])\n",
    "\n",
    "    ret = 0.\n",
    "    for i in range(len(x)):\n",
    "        ret -= avgdigamma(x[i], dvec[i])\n",
    "    ret += (\n",
    "        digamma(k)\n",
    "        - (float(len(x)) - 1.) / float(k)\n",
    "        + (float(len(x)) - 1.) * digamma(len(x[0]))\n",
    "    )\n",
    "    return ret\n",
    "\n",
    "\n",
    "def mi_LNC(X, k=5, base=np.exp(1), alpha=0.25, intens=1e-10):\n",
    "    \"\"\"The mutual information estimator by PCA-based local non-uniform correction(LNC)\n",
    "        ith row of X represents ith dimension of the data, e.g. X = [[1.0,3.0,3.0],[0.1,1.2,5.4]], if X has two dimensions and we have three samples\n",
    "        alpha is a threshold parameter related to k and d(dimensionality), please refer to our paper for details about this parameter\n",
    "    \"\"\"\n",
    "    # N is the number of samples\n",
    "    N = len(X[0])\n",
    "\n",
    "    # First Step: calculate the mutual information using the Kraskov mutual information estimator\n",
    "    # adding small noise to X, e.g., x<-X+noise\n",
    "    x = []\n",
    "    for i in range(len(X)):\n",
    "        tem = []\n",
    "        for j in range(len(X[i])):\n",
    "            tem.append([X[i][j] + intens * nr.rand(1)[0]])\n",
    "        x.append(tem)\n",
    "\n",
    "    points = []\n",
    "    for j in range(len(x[0])):\n",
    "        tem = []\n",
    "        for i in range(len(x)):\n",
    "            tem.append(x[i][j][0])\n",
    "        points.append(tem)\n",
    "    tree = cKDTree(points)\n",
    "    dvec = []\n",
    "    for i in range(len(x)):\n",
    "        dvec.append([])\n",
    "    for point in points:\n",
    "        # Find k-nearest neighbors in joint space, p=inf means max norm\n",
    "        knn = tree.query(point, k + 1, p=float(\"inf\"))\n",
    "        points_knn = []\n",
    "        for i in range(len(x)):\n",
    "            dvec[i].append(float(\"-inf\"))\n",
    "            points_knn.append([])\n",
    "        for j in range(k + 1):\n",
    "            for i in range(len(x)):\n",
    "                points_knn[i].append(points[knn[1][j]][i])\n",
    "\n",
    "        # Find distances to k-nearest neighbors in each marginal space\n",
    "        for i in range(k + 1):\n",
    "            for j in range(len(x)):\n",
    "                if dvec[j][-1] < fabs(points_knn[j][i] - points_knn[j][0]):\n",
    "                    dvec[j][-1] = fabs(points_knn[j][i] - points_knn[j][0])\n",
    "\n",
    "    ret = 0.\n",
    "    for i in range(len(x)):\n",
    "        ret -= avgdigamma(x[i], dvec[i])\n",
    "    ret += (\n",
    "        digamma(k)\n",
    "        - (float(len(x)) - 1.) / float(k)\n",
    "        + (float(len(x)) - 1.) * digamma(len(x[0]))\n",
    "    )\n",
    "\n",
    "    # Second Step: Add the correction term (Local Non-Uniform Correction)\n",
    "    e = 0.\n",
    "    tot = -1\n",
    "    for point in points:\n",
    "        tot += 1\n",
    "        # Find k-nearest neighbors in joint space, p=inf means max norm\n",
    "        knn = tree.query(point, k + 1, p=float(\"inf\"))\n",
    "        knn_points = []\n",
    "        for i in range(k + 1):\n",
    "            tem = []\n",
    "            for j in range(len(point)):\n",
    "                tem.append(points[knn[1][i]][j])\n",
    "            knn_points.append(tem)\n",
    "\n",
    "        # Substract mean\tof k-nearest neighbor points\n",
    "        for i in range(len(point)):\n",
    "            avg = knn_points[0][i]\n",
    "            for j in range(k + 1):\n",
    "                knn_points[j][i] -= avg\n",
    "\n",
    "        # Calculate covariance matrix of k-nearest neighbor points, obtain eigen vectors\n",
    "        covr = []\n",
    "        for i in range(len(point)):\n",
    "            tem = 0\n",
    "            covr.append([])\n",
    "            for j in range(len(point)):\n",
    "                covr[i].append(0)\n",
    "        for i in range(len(point)):\n",
    "            for j in range(len(point)):\n",
    "                avg = 0.\n",
    "                for ii in range(1, k + 1):\n",
    "                    avg += knn_points[ii][i] * knn_points[ii][j] / float(k)\n",
    "                covr[i][j] = avg\n",
    "        w, v = la.eig(covr)\n",
    "\n",
    "        # Calculate PCA-bounding box using eigen vectors\n",
    "        V_rect = 0\n",
    "        cur = []\n",
    "        for i in range(len(point)):\n",
    "            maxV = 0.\n",
    "            for j in range(0, k + 1):\n",
    "                tem = 0.\n",
    "                for jj in range(len(point)):\n",
    "                    tem += v[jj, i] * knn_points[j][jj]\n",
    "                if fabs(tem) > maxV:\n",
    "                    maxV = fabs(tem)\n",
    "            cur.append(maxV)\n",
    "            V_rect = V_rect + log(cur[i])\n",
    "\n",
    "        # Calculate the volume of original box\n",
    "        log_knn_dist = 0.\n",
    "        for i in range(len(dvec)):\n",
    "            log_knn_dist += log(dvec[i][tot])\n",
    "\n",
    "        # Perform local non-uniformity checking\n",
    "        if V_rect >= log_knn_dist + log(alpha):\n",
    "            V_rect = log_knn_dist\n",
    "\n",
    "        # Update correction term\n",
    "        if (log_knn_dist - V_rect) > 0:\n",
    "            e += (log_knn_dist - V_rect) / N\n",
    "\n",
    "    return (ret + e) / log(base)\n",
    "\n",
    "\n",
    "def entropy(x, k=3, base=np.exp(1), intens=1e-10):\n",
    "    \"\"\"\n",
    "    The classic K-L k-nearest neighbor continuous entropy estimator\n",
    "    x should be a list of vectors, e.g. x = [[1.3],[3.7],[5.1],[2.4]]\n",
    "    if x is a one-dimensional scalar and we have four samples\n",
    "    \"\"\"\n",
    "    assert k <= len(x) - 1, \"Set k smaller than num. samples - 1\"\n",
    "    d = len(x[0])\n",
    "    N = len(x)\n",
    "    x = [list(p + intens * nr.rand(len(x[0]))) for p in x]\n",
    "    tree = cKDTree(x)\n",
    "    nn = [tree.query(point, k + 1, p=float(\"inf\"))[0][k] for point in x]\n",
    "    const = digamma(N) - digamma(k) + d * log(2)\n",
    "    return (const + d * np.mean(map(log, nn))) / log(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = gen_x()\n",
    "y_sample = gen_y(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662 0.657 0.659\n"
     ]
    }
   ],
   "source": [
    "mi_lnc = MI.mi_LNC([x_sample.squeeze(), y_sample.squeeze()])\n",
    "mi_kraskov = MI.mi_Kraskov([x_sample.squeeze(), y_sample.squeeze()])\n",
    "print(f\"{mi_lnc:.3f} {mi_kraskov:.3f} {mi:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3 s ± 467 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mi_LNC([x_sample.squeeze(), y_sample.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.02 s ± 502 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mi_Kraskov([x_sample.squeeze(), y_sample.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 11)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = np.stack([x, y])\n",
    "xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11,)\n",
      "(11,)\n"
     ]
    }
   ],
   "source": [
    "for row in xy:\n",
    "    print(row.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "intens = 1e-10\n",
    "base = np.exp(1)\n",
    "k = 5\n",
    "x = np.stack([x_sample.squeeze()[:10], y_sample.squeeze()[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x += intens * nr.rand(*x.shape)\n",
    "x = x.T\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = cKDTree(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.        ,  0.05889131,  0.12357177,  0.51272224,  0.53690141,\n",
       "         0.55660894]), array([0, 7, 3, 4, 6, 2]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.query(x[0], k + 1, p=float(\"inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
